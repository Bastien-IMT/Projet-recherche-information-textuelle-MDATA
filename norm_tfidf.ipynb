{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from evaluation_functions import load_data, preprocess_corpus\n",
    "import time\n",
    "from src.ir_evaluation import Evaluator\n",
    "from vectoriel import Vectoriel\n",
    "\n",
    "# inheritance to modify method quickly (to normalize vector)\n",
    "class VectorielNorm(Vectoriel):\n",
    "\n",
    "    def __init__(self, corpus_tokenized, normalize=True):\n",
    "        \"\"\"\n",
    "        :param corpus_tokenized: list of documents tokenized\n",
    "        \"\"\"\n",
    "        Vectoriel.__init__(self, corpus_tokenized)\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def descripteur_ensembliste_document(self, document_bagwords, tf_idf=True):\n",
    "        \"\"\"\n",
    "        Creates tf-idf descriptor\n",
    "        :param document_bagwords: must be bag words dict {\"word\" : frequency}\n",
    "        :param tf_idf: boolean True to compute idf else False\n",
    "        :return: dict{\"token\" : idf * frequency} if tf_idf True else dict{\"token\" : frequency}\n",
    "        \"\"\"\n",
    "        result = dict()\n",
    "        # init all words to 0\n",
    "        for word in self.vocabulary:\n",
    "            result[word] = 0\n",
    "        # add frequency\n",
    "        for word in document_bagwords:\n",
    "            if word in self.vocabulary:\n",
    "                # this if statement is made to avoid to add unknown words from queries\n",
    "                tf = document_bagwords[word]\n",
    "                if not tf_idf:\n",
    "                    idf = 1\n",
    "                else:  # compute idf\n",
    "                    idf = self.compute_idf(word)\n",
    "                result[word] = tf * idf\n",
    "\n",
    "        #normalize vector\n",
    "        if self.normalize:\n",
    "            vect = list(result.values())\n",
    "            norm = np.linalg.norm(vect, 1)\n",
    "            for word, tf in zip(result, vect):\n",
    "                result[word] = tf / norm\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def eval_tfidf_norm(dataset_name='med', tf_idf=True, stop_words=True, stemm=True, bag_words=True, normalize=True):\n",
    "    \"\"\"\n",
    "    Evaluates performances of ensembliste SRI with a given dataset name\n",
    "    Boolean parameters allows to see their impacts in the SRI performances\n",
    "    :param normalize: boolean to make vector norm = 1\n",
    "    :param tf_idf: boolean\n",
    "    :param dataset_name: str\n",
    "    :param stop_words: boolean\n",
    "    :param stemm: boolean\n",
    "    :param bag_words: boolean\n",
    "    :return: dictionary 'result'\n",
    "    \"\"\"\n",
    "    dataset, queries, ground_truth = load_data(dataset_name)\n",
    "    stop_list = np.genfromtxt('data/stoplist/stoplist-english.txt', dtype='str')\n",
    "    dataset_bagwords = preprocess_corpus(dataset, stop_list, stop_words=stop_words, stemm=stemm, bag_words=bag_words)\n",
    "\n",
    "    ground_truth_dict = dict()\n",
    "    ground_truth_dict['groundtruth'] = ground_truth\n",
    "\n",
    "    vectoriel = VectorielNorm(dataset_bagwords, normalize=normalize)\n",
    "    result = dict()\n",
    "\n",
    "    # Inverted index\n",
    "    # Compute time to build inverted index\n",
    "    start_inverted_build = time.time()\n",
    "    index_inverted = vectoriel.inverted_index_construction(dataset_bagwords, tf_idf=tf_idf)\n",
    "    stop_inverted_build = time.time()\n",
    "    result['inverted_build_time'] = stop_inverted_build - start_inverted_build\n",
    "\n",
    "    # Compute time to search in inverted index\n",
    "    start_search_inverted = time.time()\n",
    "    eval_inverted_all_queries = vectoriel.search_all_queries(queries, inverted=True, tf_idf=tf_idf,\n",
    "                                                             stop_words=stop_words, stemm=stemm, bag_words=bag_words)\n",
    "    end_search_inverted = time.time()\n",
    "    result['inverted_search_time'] = end_search_inverted - start_search_inverted\n",
    "\n",
    "    # Evaluate performances (recall precision)\n",
    "    eval_inverted = Evaluator(retrieved=eval_inverted_all_queries, relevant=ground_truth_dict)\n",
    "    result[\"evaluation_inverted\"] = eval_inverted.evaluate_pr_points()\n",
    "\n",
    "    result[\"MAP inverted\"] = eval_inverted.evaluate_map()\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dataset = 'lisa'\n",
    "results = dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results[\"norm\"] = eval_tfidf_norm(dataset, stop_words=True, stemm=True, bag_words=True, normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results[\"no_norm\"] = eval_tfidf_norm(dataset, stop_words=True, stemm=True, bag_words=True, normalize=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_precision_recall(evaluation_list, labels):\n",
    "    \"\"\"\n",
    "    Plots multiple recall-precision curves on same plot (for comparison)\n",
    "    :param evaluation_list: list of tuples [(x1, y1), (x2, y2), ...]\n",
    "    :param labels: curves title\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    for evaluation, label in zip(evaluation_list, labels):\n",
    "        plt.plot([e[0] for e in evaluation], [e[1] for e in evaluation], label=label)\n",
    "    plt.grid()\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_precision_recall([results['norm']['evaluation_inverted'], results['no_norm']['evaluation_inverted']], ['tf_idf MED norm', 'tf_idf MED no norm'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-b574e03b",
   "language": "python",
   "display_name": "PyCharm (scientificProject)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}